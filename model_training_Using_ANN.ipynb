{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu5jIVzXPYey"
      },
      "outputs": [],
      "source": [
        "#Problem Statement:-Suppose as a Bank Manager the target is to guess who are the churn  customer.\n",
        "#Churn  customer means who had low credit score, less touch within the respective bank branches\n",
        "#may be there bank account will be closed soon\n",
        "\n",
        "#Using ANN we will solve here the classification types of Problem.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading the data\n",
        "data=pd.read_csv('/content/Churn_Modelling.csv')\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "HS-4kZhfREoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the data\n",
        "#Drop the unnecessary columns\n",
        "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)"
      ],
      "metadata": {
        "id": "jy6JOcCXSbfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d526611"
      },
      "source": [
        "with open(\"scaler.pkl\",'wb') as file:\n",
        "    pickle.dump(scaler,file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f49fcc2f"
      },
      "source": [
        "from google.colab import files\n",
        "#files.download('scaler.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing the labelEncoding Operation for Gender\n",
        "label_encoder_gender=LabelEncoder()#Creating the instance with respect to the label Encoder\n",
        "data['Gender']=label_encoder_gender.fit_transform(data['Gender'])\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "_6TPMBiTS5V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For the geography we will use the OneHotEncoder\n",
        "Onehot_encoder_geography=OneHotEncoder()#Creating the instance\n",
        "geo_encoder=Onehot_encoder_geography.fit_transform(data[['Geography']]).toarray()\n",
        "geo_encoder"
      ],
      "metadata": {
        "id": "ER29WthWT05I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Observe the data\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "IpVybBImVFni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting the Geography features name using OHE\n",
        "l=Onehot_encoder_geography.get_feature_names_out(['Geography'])\n",
        "l"
      ],
      "metadata": {
        "id": "JG5-8acdVNxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Pandas DataFrame for ['Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
        "geo_encoded_df=pd.DataFrame(geo_encoder,columns=l)\n",
        "geo_encoded_df"
      ],
      "metadata": {
        "id": "FGN5M9jfVsgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#All the columns Except Geography\n",
        "x=data.drop('Geography',axis=1)\n",
        "x.columns"
      ],
      "metadata": {
        "id": "TOZcJ7wzWQq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine the ONEHOT ['Geography_France', 'Geography_Germany', 'Geography_Spain'] columns with original\n",
        "#data\n",
        "#Combined x and geo_encoded_df\n",
        "data=pd.concat([x,geo_encoded_df],axis=1)\n",
        "data"
      ],
      "metadata": {
        "id": "Vo3CNJyRWpmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the encoders and scalers in pickle file format\n",
        "#I want to create one label_encoder_gender.pkl file in write binary mode from label_encoder_gender\n",
        "with open(\"label_encoder_gender.pkl\",'wb') as file:\n",
        "    pickle.dump(label_encoder_gender,file)\n",
        "\n",
        "\n",
        "with open(\"onehot_encoder_geo.pkl\",'wb') as file:\n",
        "    pickle.dump(Onehot_encoder_geography,file)"
      ],
      "metadata": {
        "id": "k-4WGRH1XpD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividing the data into dependent and independent features\n",
        "X=data.drop('Exited',axis=1)#Input features\n",
        "y=data['Exited']#Target Features"
      ],
      "metadata": {
        "id": "hsQxs2JMZuqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting the data into train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "3HYGuskyaKBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Large value is present.I have to scalized this value\n",
        "#1000=0.1\n",
        "#2000=0.2\n",
        "#3000=0.3\n",
        "X_train\n",
        "X_test"
      ],
      "metadata": {
        "id": "29d0dRd1agDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the features\n",
        "scaler=StandardScaler()#Creating the instance for the scaler\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "BLA9-VVJa1ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The value has been scalized\n",
        "X_train\n",
        "X_test"
      ],
      "metadata": {
        "id": "G2sOEmRXbPiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN MODEL BUILD"
      ],
      "metadata": {
        "id": "YtoA1Y3ihAcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential# Mainly use to start Neural Network\n",
        "from tensorflow.keras.layers import Dense# Use for the hidden and output layer\n",
        "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
        "import datetime"
      ],
      "metadata": {
        "id": "IXCS5u_ZbXRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "Z-u_fuZehvLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Built ANN model\n",
        "model=Sequential([\n",
        "\n",
        "                  Dense(64,activation='relu',input_dim=X_train.shape[1]),#First Hidden Layer\n",
        "                  Dense(32,activation='relu'),#Second Hidden Layer\n",
        "                  Dense(1,activation='sigmoid')#Output\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "vkF2PeX9hxOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LRC8aoE6iw4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss=tf.keras.losses.BinaryCrossentropy()\n",
        "loss"
      ],
      "metadata": {
        "id": "b1HS5WLgjGpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the models\n",
        "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "12SZSGaMjNH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)"
      ],
      "metadata": {
        "id": "8pj8-OGPkywc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set up Early Stopping\n",
        "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "LqxhR6zGmmFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train the model\n",
        "history=model.fit(\n",
        "    X_train,y_train,validation_data=(X_test,y_test),epochs=100,\n",
        "    callbacks=[tensorflow_callback,early_stopping_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "nkJQKOpdkzgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#It's the file to connecting it with Front-end part\n",
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "id": "z4H56dzonXrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Tensorboard Extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "tuW10KEen13P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "-8EcEbA4n4Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "i8TwjktPSmto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}